[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)
[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://www.python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-Backend-brightgreen.svg)](https://fastapi.tiangolo.com/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.x-orange.svg)](https://pytorch.org)

# Beat Monitor ‚Äì Neural Audio Fingerprinting (Version adapt√©e)

## √Ä propos du projet

### Le d√©fi
Comment garantir une **r√©mun√©ration √©quitable des artistes** quand la surveillance manuelle des diffusions est impossible √† l'√©chelle nationale ?

### Notre r√©ponse
**Beat Monitor**, d√©velopp√© avec **DataLab**, d√©ploie l'IA au service de la propri√©t√© intellectuelle. Le syst√®me **NeuralFP** identifie automatiquement chaque ≈ìuvre diffus√©e, qu'elle passe sur une radio en ligne ou une t√©l√©vision.

### Le gain
‚úÖ **Z√©ro d√©claration manuelle**  
‚úÖ **Tra√ßabilit√© totale**  
‚úÖ **Droits d'auteur calcul√©s automatiquement** et redistribu√©s √©quitablement  

**Pour le BBDA (Bureau Burkinab√© du Droit d'Auteur), c'est une r√©volution.**

---

## üéØ Fonctionnalit√©s cl√©s

Beat Monitor utilise un mod√®le de **Neural Audio Fingerprinting (NeuralFP)** bas√© sur l'apprentissage contrastif pour :

- üéµ G√©n√©rer des empreintes audio robustes
- üîç Identifier automatiquement une musique √† partir d'un court extrait
- ‚è±Ô∏è D√©tecter les diffusions en temps r√©el ou en mode batch
- üí∞ Aider √† la r√©mun√©ration √©quitable des artistes

Cette version est adapt√©e pour le **d√©ploiement national au Burkina Faso**.

---

## üéµ Mod√®le source

Ce projet utilise le code source du mod√®le **Neural Audio Fingerprinting** d√©velopp√© par :

**üì¶ D√©p√¥t officiel :** [github.com/mimbres/neural-audio-fp](https://github.com/mimbres/neural-audio-fp)

### Modifications principales apport√©es

| Aspect | Version originale | Notre adaptation |
|--------|------------------|------------------|
| **Strat√©gie d'identification** | Requ√™tes ponctuelles (query-based) | **Surveillance continue en streaming** |
| **Fonction de loss** | Cross-Entropy (Xent) | **Triplet Loss** (meilleure robustesse) |
| **Cas d'usage** | Identification √† la demande | Monitoring 24/7 multi-radios |

### Pourquoi ces changements ?

‚úÖ **Triplet Loss** : Am√©liore la s√©paration des embeddings et la robustesse au bruit  
‚úÖ **Surveillance continue** : D√©tection automatique sans intervention manuelle  
‚úÖ **Architecture temps r√©el** : Streaming audio + d√©tection par segments cons√©cutifs

---

## ‚öôÔ∏è Technologies utilis√©es

### **Backend**
- Python 3.9+
- FastAPI (API REST)
- Uvicorn (serveur ASGI)
- Tensorflow 2.x (mod√®le NeuralFP)
- Librosa (traitement audio)
- FFmpeg (d√©codage streams)

### **Frontend**
- Angular 18+
- PrimeNG (UI components)
- Chart.js (visualisations)
- WebSocket (temps r√©el)

### **Matching & Database**
- Faiss (Facebook AI Similarity Search)
- SQLite (stockage d√©tections)
- NumPy / SciPy (calculs scientifiques)
- Embeddings audio 128D (NeuralFP)